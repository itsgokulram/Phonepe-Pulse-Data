{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import mysql.connector\n",
    "import sqlalchemy\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.0.22)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from SQLAlchemy) (4.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA cloned in terminal\n",
    "\n",
    "# command: git clone (git file path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3954, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Aggregated transaction\n",
    "\n",
    "path = \"/Users/gokul/My Apple/vs_code_practice/pulse/data/aggregated/transaction/country/india/state\"\n",
    "\n",
    "agg_trans_list = os.listdir(path)\n",
    "\n",
    "columns = { 'State': [], 'Year': [], 'Quarter': [], 'Transaction_type': [], 'Transaction_count': [], 'Transaction_amount': [] }\n",
    "\n",
    "ignored = {\".DS_Store\"}\n",
    "\n",
    "for state in agg_trans_list:\n",
    "    # print(state)\n",
    "    if state not in ignored:\n",
    "\n",
    "        state_path = path + \"/\" + state\n",
    "        state_files = os.listdir(state_path)\n",
    "\n",
    "        for year in state_files:\n",
    "\n",
    "            if year not in ignored:\n",
    "\n",
    "                year_path = state_path + \"/\" + year\n",
    "                # print(year_path)\n",
    "                quat_file = os.listdir(year_path)\n",
    "                # print(quat_file)\n",
    "\n",
    "                for files in quat_file:\n",
    "                    \n",
    "                    trans_file = year_path + \"/\" + files\n",
    "                    # print(trans_file)\n",
    "                    data = open(trans_file, 'r')\n",
    "                    A = json.load(data)\n",
    "\n",
    "                    for i in A['data']['transactionData']:\n",
    "\n",
    "                        type = i['name']\n",
    "                        count = i['paymentInstruments'][0]['count']\n",
    "                        amount = i['paymentInstruments'][0]['amount']\n",
    "                        \n",
    "                        columns['State'].append(state)\n",
    "                        columns['Year'].append(year)\n",
    "                        columns['Quarter'].append(int(files.strip('.json')))\n",
    "                        columns['Transaction_type'].append(type)\n",
    "                        columns['Transaction_count'].append(count)\n",
    "                        columns['Transaction_amount'].append(amount)\n",
    "\n",
    "df_agg_trans = pd.DataFrame(columns)\n",
    "# print(df_agg_trans.head(10))\n",
    "df_agg_trans.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6732, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(792, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Aggregated User\n",
    "# Data Aggregated User summary\n",
    "\n",
    "path_2 = \"/Users/gokul/My Apple/vs_code_practice/pulse/data/aggregated/user/country/india/state\"\n",
    "\n",
    "agg_user_list = os.listdir(path_2)\n",
    "\n",
    "columns_1 = {'State' : [], 'Year': [], 'Quarter': [], 'Brand': [], 'Count': [], 'Percentage': []}\n",
    "columns_2 = {'State': [], 'Year': [], 'Quarter': [], 'Registered users': [], 'App openings': [] }\n",
    "\n",
    "ignored = {\".DS_Store\"}\n",
    "\n",
    "for state in agg_user_list:\n",
    "    # print(state)\n",
    "    if state not in ignored:\n",
    "\n",
    "        state_path = path_2 + \"/\" + state\n",
    "        state_files = os.listdir(state_path)\n",
    "\n",
    "        for year in state_files:\n",
    "\n",
    "            if year not in ignored:\n",
    "\n",
    "                year_path = state_path + \"/\" + year\n",
    "                # print(year_path)\n",
    "                quat_file = os.listdir(year_path)\n",
    "                # print(quat_file)\n",
    "\n",
    "                for files in quat_file:\n",
    "                    \n",
    "                    user_file = year_path + \"/\" + files\n",
    "                    data = open(user_file, 'r')\n",
    "                    B = json.load(data)\n",
    "\n",
    "                    reg_users = B['data']['aggregated']['registeredUsers']\n",
    "                    app_openings = B['data']['aggregated']['appOpens']\n",
    "                    columns_2['State'].append(state)\n",
    "                    columns_2['Year'].append(year)\n",
    "                    columns_2['Quarter'].append(files.strip('.json'))\n",
    "                    columns_2['Registered users'].append(reg_users)\n",
    "                    columns_2['App openings'].append(app_openings)\n",
    "\n",
    "                    try:\n",
    "\n",
    "                        for i in B['data']['usersByDevice']:\n",
    "\n",
    "                            brand_name = i['brand']\n",
    "                            count = i['count']\n",
    "                            percentage = i['percentage']\n",
    "\n",
    "                            columns_1['State'].append(state)\n",
    "                            columns_1['Year'].append(year)\n",
    "                            columns_1['Quarter'].append(int(files.strip('.json')))\n",
    "                            columns_1['Brand'].append(brand_name)\n",
    "                            columns_1['Count'].append(count)\n",
    "                            columns_1['Percentage'].append(percentage)\n",
    "\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "df_agg_users = pd.DataFrame(columns_1)\n",
    "df_agg_users_summary = pd.DataFrame(columns_2)\n",
    "\n",
    "# print(df_agg_users.head(20))\n",
    "print(df_agg_users.shape)\n",
    "# print(df_agg_users_summary.head(10))\n",
    "df_agg_users_summary.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16100, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data map transaction\n",
    "\n",
    "path_3 = \"/Users/gokul/My Apple/vs_code_practice/pulse/data/map/transaction/hover/country/india/state\"\n",
    "\n",
    "map_trans_list = os.listdir(path_3)\n",
    "\n",
    "columns_3 = {'District': [], 'State' : [], 'Year': [], 'Quarter': [], 'Count': [], 'Amount': []}\n",
    "\n",
    "ignored = {\".DS_Store\"}\n",
    "\n",
    "for state in map_trans_list:\n",
    "    # print(state)\n",
    "    if state not in ignored:\n",
    "\n",
    "        state_path = path_3 + \"/\" + state\n",
    "        state_files = os.listdir(state_path)\n",
    "\n",
    "        for year in state_files:\n",
    "\n",
    "            if year not in ignored:\n",
    "\n",
    "                year_path = state_path + \"/\" + year\n",
    "                # print(year_path)\n",
    "                quat_file = os.listdir(year_path)\n",
    "                # print(quat_file)\n",
    "\n",
    "                for files in quat_file:\n",
    "                    \n",
    "                    trans_file = year_path + \"/\" + files\n",
    "                    data = open(trans_file, 'r')\n",
    "                    C = json.load(data)\n",
    "\n",
    "                    for i in C['data']['hoverDataList']:\n",
    "\n",
    "                        district = i['name']\n",
    "                        count = i['metric'][0]['count']\n",
    "                        amount = i['metric'][0]['amount']\n",
    "\n",
    "                        columns_3['State'].append(state)\n",
    "                        columns_3['District'].append(district)\n",
    "                        columns_3['Year'].append(year)\n",
    "                        columns_3['Quarter'].append(int(files.strip('.json')))\n",
    "                        columns_3['Count'].append(count)\n",
    "                        columns_3['Amount'].append(amount)\n",
    "\n",
    "df_map_trans = pd.DataFrame(columns_3)\n",
    "\n",
    "# print(df_map_trans.head(15))\n",
    "df_map_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16104, 6)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Map User\n",
    "\n",
    "path_4 = \"/Users/gokul/My Apple/vs_code_practice/pulse/data/map/user/hover/country/india/state\"\n",
    "\n",
    "map_user_list = os.listdir(path_4)\n",
    "\n",
    "columns_4 = {'district': [], 'state': [], 'year': [], 'quarter': [], 'registered_users': [], 'app_openings': [] }\n",
    "\n",
    "ignored = {\".DS_Store\"}\n",
    "\n",
    "for state in map_user_list:\n",
    "    \n",
    "    if state not in ignored:\n",
    "\n",
    "        state_path = path_4 + \"/\" + state\n",
    "        state_files = os.listdir(state_path)\n",
    "\n",
    "        for year in state_files:\n",
    "            \n",
    "            if year not in ignored:\n",
    "\n",
    "                year_path = state_path + \"/\" + year\n",
    "                quat_file = os.listdir(year_path)\n",
    "\n",
    "                for files in quat_file:\n",
    "                    \n",
    "                    user_file = year_path + \"/\" + files\n",
    "                    data = open(user_file, 'r')\n",
    "                    D = json.load(data)\n",
    "\n",
    "                    temp = D['data']['hoverData']\n",
    "\n",
    "                    for i in D['data']['hoverData']:\n",
    "\n",
    "                        district = i\n",
    "                        # print(district)\n",
    "                        reg_users = temp[i]['registeredUsers']\n",
    "                        app_opens = temp[i]['appOpens']\n",
    "\n",
    "                        columns_4['district'].append(district)\n",
    "                        columns_4['state'].append(state)\n",
    "                        columns_4['year'].append(year)\n",
    "                        columns_4['quarter'].append(int(files.strip('.json')))\n",
    "                        columns_4['registered_users'].append(reg_users)\n",
    "                        columns_4['app_openings'].append(app_opens)\n",
    "\n",
    "df_map_users = pd.DataFrame(columns_4)\n",
    "# print(df_map_user.head(10))\n",
    "df_map_users.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7853, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Transactions\n",
    "\n",
    "path_5 = \"/Users/gokul/My Apple/vs_code_practice/pulse/data/top/transaction/country/india/state\"\n",
    "\n",
    "top_trans_list = os.listdir(path_5)\n",
    "\n",
    "columns_5 = { 'State': [], 'Year': [], 'Quarter': [], 'Pincode': [], 'Count': [], 'Amount': []}\n",
    "\n",
    "ignored = {\".DS_Store\"}\n",
    "\n",
    "for state in top_trans_list:\n",
    "\n",
    "    if state not in ignored:\n",
    "\n",
    "        state_path = path_5 + \"/\" + state\n",
    "        state_files = os.listdir(state_path)\n",
    "\n",
    "        for year in state_files:\n",
    "\n",
    "            year_path = state_path + \"/\" + year\n",
    "            quat_file = os.listdir(year_path)\n",
    "\n",
    "            for files in quat_file:\n",
    "\n",
    "                top_trans_file = year_path + \"/\" + files\n",
    "                data = open(top_trans_file, 'r')\n",
    "                E = json.load(data)\n",
    "\n",
    "                for i in E['data']['pincodes']:\n",
    "                    \n",
    "                    pincode = i['entityName']\n",
    "                    count = i['metric']['count']\n",
    "                    amount = i['metric']['amount']\n",
    "\n",
    "                    columns_5['State'].append(state)\n",
    "                    columns_5['Year'].append(year)\n",
    "                    columns_5['Quarter'].append(int(files.strip('.json')))\n",
    "                    columns_5['Pincode'].append(pincode)\n",
    "                    columns_5['Count'].append(count)\n",
    "                    columns_5['Amount'].append(amount)\n",
    "\n",
    "df_top_trans = pd.DataFrame(columns_5)\n",
    "\n",
    "# print(df_top_trans.head(10))\n",
    "df_top_trans.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7854, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top User data\n",
    "\n",
    "path_6 = \"/Users/gokul/My Apple/vs_code_practice/pulse/data/top/user/country/india/state\"\n",
    "\n",
    "top_user_list = os.listdir(path_6)\n",
    "\n",
    "columns_6 = { 'State': [], 'Year': [], 'Quarter': [], 'Pincode': [], 'Registered users': [] }\n",
    "\n",
    "ignored = {\".DS_Store\"}\n",
    "\n",
    "for state in top_user_list:\n",
    "\n",
    "    if state not in ignored:\n",
    "\n",
    "        state_path = path_6 + \"/\" + state\n",
    "        state_files = os.listdir(state_path)\n",
    "\n",
    "        for year in state_files:\n",
    "\n",
    "            year_path = state_path + \"/\" + year\n",
    "            quat_file = os.listdir(year_path)\n",
    "\n",
    "            for files in quat_file:\n",
    "\n",
    "                top_user_file = year_path + \"/\" + files\n",
    "                data = open(top_user_file, \"r\")\n",
    "                F = json.load(data)\n",
    "\n",
    "                for i in F['data']['pincodes']:\n",
    "\n",
    "                    pincode = i['name']\n",
    "                    reg_users = i['registeredUsers']\n",
    "\n",
    "                    columns_6['State'].append(state)\n",
    "                    columns_6['Year'].append(year)\n",
    "                    columns_6['Quarter'].append(int(files.strip('.json')))\n",
    "                    columns_6['Pincode'].append(pincode)\n",
    "                    columns_6['Registered users'].append(reg_users)\n",
    "\n",
    "df_top_users = pd.DataFrame(columns_6)\n",
    "\n",
    "# print(df_top_user.head(10))\n",
    "\n",
    "df_top_users.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x15d0cef50>\n"
     ]
    }
   ],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"\",\n",
    ")\n",
    "\n",
    "print(mydb)\n",
    "mycursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"CREATE DATABASE Phonepe_pulse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"USE Phonepe_pulse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING TABLES IN SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Aggregated transaction\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS agg_trans( state VARCHAR(120), year INT, quarter INT, transaction_type VARCHAR(100), transaction_count INT, transaction_amount DOUBLE)\")\n",
    "\n",
    "# Data Aggregated User\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS agg_users( state VARCHAR(120), year INT, quarter INT, brand VARCHAR(100), count INT, percentage DOUBLE)\")\n",
    "\n",
    "# Data Aggregated User summary\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS agg_users_summary( state VARCHAR(120), year INT, quarter INT, registered_users VARCHAR(100), app_openings INT)\")\n",
    "\n",
    "# Data map transaction\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS map_trans( district VARCHAR(150), state VARCHAR(120), year INT, quarter INT, count INT, amount DOUBLE)\")\n",
    "\n",
    "# Data Map User\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS map_users( district VARCHAR(150), state VARCHAR(120), year INT, quarter INT, registered_users VARCHAR(100), app_openings INT)\")\n",
    "\n",
    "# Top Transactions\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS top_trans( state VARCHAR(120), year INT, quarter INT, pincode INT, count INT, amount INT)\")\n",
    "\n",
    "# Top User data\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS top_users( state VARCHAR(120), year INT, quarter INT, pincode INT, registered_users INT)\")\n",
    "\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS map_users( district VARCHAR(150), state VARCHAR(120), year INT, quarter INT, registered_users VARCHAR(100), app_openings INT)\")\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUSHING data into SQL\n",
    "# creating engine to push the data\n",
    "\n",
    "database_username = \"root\"\n",
    "database_password = \"\"\n",
    "database_ip       = \"localhost\"\n",
    "database_name     = \"Phonepe_pulse\"\n",
    "database_connection = sqlalchemy.create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                               format(database_username, database_password, \n",
    "                                                      database_ip, database_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7854"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inserting data into SQL tables\n",
    "\n",
    "df_agg_trans.to_sql(con = database_connection, name='agg_trans', if_exists='replace')\n",
    "\n",
    "\n",
    "df_agg_users.to_sql(con = database_connection, name='agg_users', if_exists='replace')\n",
    "\n",
    "\n",
    "df_agg_users_summary.to_sql(con = database_connection, name='agg_users_summary', if_exists='replace')\n",
    "\n",
    "\n",
    "df_map_trans.to_sql(con = database_connection, name='map_trans', if_exists='replace')\n",
    "\n",
    "\n",
    "df_map_users.to_sql(con = database_connection, name='map_users', if_exists='replace')\n",
    "\n",
    "\n",
    "df_top_trans.to_sql(con = database_connection, name='top_trans', if_exists='replace')\n",
    "\n",
    "\n",
    "df_top_users.to_sql(con = database_connection, name='top_users', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16104"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_users.to_sql(con = database_connection, name='map_users', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('agg_trans',),\n",
       " ('agg_users',),\n",
       " ('agg_users_summary',),\n",
       " ('map_trans',),\n",
       " ('map_users',),\n",
       " ('top_trans',),\n",
       " ('top_users',)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycursor.execute(\"show tables\")\n",
    "mycursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data insertion completed "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
